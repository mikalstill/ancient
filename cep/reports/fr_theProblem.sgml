<title>The Problem</title>

<para>
Various organisations around the world collect data from a variety of sources, such as GPS, VLBI and SLR monitoring stations. This data provides information regarding among other things, tectonic plate movement. This allows organisations to draw conclusions to the level of continental drift, ocean levels, etc.
</para>

<para>
Before the data can be interpreted, it must be processed. This, as with most raw data, involves shaping it into a format which can be readily understood by people, and in almost all cases software. Information from data is general more readily extracted from graphical forms, enabling for example, trends in the data to be seen if they exist. The next step is to be able to take into consideration various circumstances that may arrise during monitoring. There may be changes in equipment, malfunctionions, bad or whether, or as many cases, noise in the data. Before drawing any conlusions from the data, people need to be certain that they are dealing with only the necessary information.
<para/>

<para>
It is at this point, that software becomes an important tool. It can be used to model certain situtations or remove unwanted data. For example if a know malfunction was noted at a given time, the modelling process can deal with this event by perhaps removing the data, or applying we-weighting algorithms to the data etc. 
</para>

<para>
In many cases with data analysis, there is a need to view different representions of the data, for example, in the Frequency Domain. Once again, this may allow the identification of trend or patterns. What happens when the frequency of the monitoring decreases or increases? Such questions can assist in more accurate and informed conlcusions as to what exactly the data is saying.
</para>