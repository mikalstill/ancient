<sect1><title>Interpolation</title>

<sect2><title>Introduction</title>
  <para>One of the problems with the GPS datasets we analyse is missing observations.
  Missing data points skew data results and prevent transformation into the fourier
  domain by means of fast fourier transform.  Another problem is that the time scale
  that has been provided for these datasets is not linear.  To overcome these problems
  our application provides interpolation function that can be used to fill in missing
  data points.  However the accuracy of any interpolation method will vary depending
  on the dataset that it is applied to so Six different methods of interpolation have
  been provided.
  </para>
</sect2> <!--Introduction-->

<sect2><title>Theory</title>
  <para>
  Theoretically each of the datasets that we analyse should be sampled once a day at
  exactly twelve o'clock.  However we live in the real world and for reasons such as
  equipment failure, extreme weather and local politics some samples are missing.
  </para>
  <para>
  The fourier transform algorithms available to us require that the dataset be regular.
  This means that if a dataset is missing a point or has an irregular sample rate then
  it can't be transferred to the frequency domain.  The dataset has to be made regular
  either by removing points or interpolating new points.
  </para>
  <para>
  This irregular sampling rate has been compounded by having the datasets stored on a
  non-linear time scale.  The data that we have been provided has been sampled regurarly
  once a day at noon as timed by an atomic clock; so the sample rate is pretty regular.
  However the sample date/time has then been stored in decimal year format to 8 significant
  figures.  Ignoring machine rounding errors this creates a problem.  During a regular
  year one day is 0.00273972.  However one in every four years is a leap year and the
  length of a day is 0.00273224, a smaller number.  Also at the start of each year a
  rounding occurs so that the first reading of the year occurs at XXXX.0014.  This
  rounding creates the illusion different time distance again to be between the last
  day of one year and the first day of the next.  In short before interpolation can
  occur a new time scale independant of calendar years has to be built.
  </para>
  <para>
  The new time scale that we convert to is what is known as a truncated Julian day.
  The julian day system uses an integer day count since the first of January 4714 BC.
  However because this produces extremely large numbers which could potentially cause
  loss of accuracy due to machine limitations.  To prevent this we have used the first
  of January 1901 as our start date.  The existing decimal dates then converted to
  truncated Julian day and rounded to the nearest whole number.  Once the timescale
  is linear the data can be interpolated without fear of loss.
  </para>
  <para>
  Different interpolation methods have different strengths and weaknesses.  On an
  arbitary dataset it is impossible to tell which interpolation method will be
  the most accurate.  To this end six different interpolation methods have been
  provided, each will be outlined below on its operation, strengths and weaknesses.
  </para>

  <sect3><title>Nearest Neighbour Interpolation</title>
  <para>
    The simplest interpolation method provided.  Nearest neighbour interpolation
    simply set the value of any new point to the value of the nearest point on the
    original dataset.  The advantage of this is that any added points will be of
    the same approximate value as nearby points.  There are a number of disadvantages
    with nearest neighbour approximation.  Firstly any new points will not follow
    any linear or frequency trends in the data, this could lead to inaccuracy of
    models both in the time and frequency domains.  Also if new points lie close to
    outliers then very inaccurate point may be generated
  </para>
  </sect3>

  <sect3><title>Linear Interpolation</title>
  <para>
    Nearest neighbour interpolation is widely used because it is still simple yet
    generally produces better results than nearest neighbour.  To do nearest neighbour
    interpolation each new point is placed on a line between the two adjacent points.
    The Equation for adding a new point is: (TODO:ADD LINEAR INTERP EQUATION 1)
  </para>

  <para>
    where: (TODO:ADD LINEAR INTERP EQUATION 2)
  </para>
  <para>
    Linear interpolation has several advantages.  Firstly each added point has a
    value that is approximately the same as nearby value; this means badly out of
    range value are very rare.  Secondly the added point will follow any local
    linear trends between the two points.
  </para>
  <para>
    The disadvantages of linear interp stem from the interpolation method only working
    with the two adjacent points. If the line between these two points does not follow
    the overall trend of the data then loss of accuracy occurs.
  </para>
  </sect3>

  <sect3><title>Natural Spline Interpolation</title>
  <para>
    Natural splines are a type of cubic spline.  The idea of cubic splines comes
    from ancient times when builders would create a smooth curve by pegging a
    flexible piece of wood between a number of points.  Cubic splines are a method
    of recreating this wooden curve with mathematics.  With all cubic splines the
    interpolation is done by inserting a cubic between each two adjacent points.
    At the linking points these cubics must have the same first and sescond
    derivatives.  Equalizing the derivatives has the effect of making the resulting
    interpolation appear smooth and visually appleasing.  For this reason splines
    are often used in graphics.
  </para>
  <para>
    In the mathematical process of building splines it is impossible to infer the
    dervatives of the two end points of a dataset.  It is the values assigned to
    these end points that determine the type of spine.  In a natural spline the
    end points are set to 0.  This gives a result similar to the ancient wooden
    splines used by builders.  Mathematically this is ment to protruce a result
    where the end segments are a bit too straight.
  </para>
  <para>
    To produce a spine for a dataset of n+1 points you have to produce n seperate
    cubics.  Each of these cubic should have each end match up exactly with the
    points to either side.  And on the same point the two adjacent cubic should
    have shared first and second derivitives.
  </para>
  <para>
    Each of these cubics can be described by the equation: (TODO: Spline equation 1)
  </para>
  <para>
    Because each of these cubics begins at a point we can say: (TODO: Spline equation 2)
  </para>
  <para>
    Let h<subscript>i</subscript>=(x<subscript>i+1</subscript> - x<subscript>i</subscript>),
    be the width of the ith interval.
  </para>
  <para>
    Also if we make s the set of second derivitives; then through algebraic simplification
    we can get: (TODO: Spline eqations 3,4,5)
  </para>
  <para>
    With natural splines solving for S is done by solving:
  </para>
  <para>
    A full mathematical derivation can be found in Gerald &amp; Wheatley 1999, page 238.
  </para>
  </sect3>
  <sect3><title>Foobar</title>
  <para>
  For example a cubic spline interpolation provides a smooth curve with no instantaneous slope
  changes.  The advantage of cubic splines is that provided with a high sample rate system
  it can create a highly accurate model.  However cubic splines tend to produce
  unrealistic bulges in the data
  </para>

  <para>
    ideas:
    -req'd for data to be FFT'd - FFT data must be regular
    -provides models for periods where data is not available
    -need several techniques as no single technq. suits all applications.
   </para>
  </sect3>
</sect2> <!--Theory-->

<sect2><title>Conclusion</title>
  <para></para>
</sect2> <!--Conclusion-->


</sect1> <!--Interpolation-->

