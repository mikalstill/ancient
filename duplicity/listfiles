#!/usr/bin/python

"""What files are backed up on this media?"""

import sys
sys.path.append('/data/src/stillhq_public/trunk/python/')

import datetime
import os
import random
import re
import subprocess
import time
import traceback
import MySQLdb

import cachedexecution
import gflags
import sql


FLAGS = gflags.FLAGS
gflags.DEFINE_string('dbuser', 'duplicity', 'DB username')
gflags.DEFINE_string('dbpassword', 'duplicity', 'DB user password')
gflags.DEFINE_string('dbname', 'duplicity', 'DB name')

gflags.DEFINE_string('media', '', 'The name of the backup media')
gflags.DEFINE_string('path', '', 'The path to the backup media')

gflags.DEFINE_boolean('pool', False, 'Process backups in parallel')


SCRIPTS_PATH = '/data/src/stillhq_public/trunk/duplicity'
VERBOSE = False

# Thu Apr 28 13:54:45 2011 www.old/index.html
FILE_RE = re.compile('  ([^ ]+) ([^ ]+) .* \(([0-9]+)\)$')

# duplicity-full-signatures.20110824T155213Z.sigtar.gz
FULL_BACKUP_RE = re.compile('duplicity-full-signatures.'
                            '([0-9][0-9][0-9][0-9])([0-9][0-9])([0-9][0-9])T'
                            '([0-9][0-9])([0-9][0-9])([0-9][0-9])')

BACKUP_GAP = datetime.timedelta(hours=1)

filesystem_inserts = []
version_inserts = []
version_updates = []

start_time = time.time()
db_time = 0


def PrintProgress(cursor, extra=''):
  global total_days
  global completed_days
  global start_time
  global db_time

  cursor.execute('select count(*) from filesystem;')
  unique_files = cursor.fetchone()['count(*)']
  cursor.execute('select count(*) from versions;')
  unique_versions = cursor.fetchone()['count(*)']

  run_time = time.time() - start_time

  print ('%s: %d unique files, %d unique versions, '
         '%.02f sec wall, %.02f sec db%s'
         %(datetime.datetime.now(), unique_files, unique_versions, 
           run_time, db_time, extra))


def TraceBack():
  exc = None
    
  try:
    exc = sys.exc_info()
    for tb in traceback.format_exception(exc[0], exc[1], exc[2]):
      print '  %s' % tb
      del tb

  finally:
    del exc

  sys.exit(1)


def CommitChanges(cursor, retry=True):
  global filesystem_inserts
  global version_inserts
  global version_updates
  global db_time

  db_start = time.time()

  try:
    if filesystem_inserts:
      s = ('insert ignore into filesystem (filename, parent) values %s;'
           % ','.join(filesystem_inserts))
      cursor.execute(s)
      cursor.execute('commit;')
      filesystem_inserts = []

    if version_inserts:
      s = ('insert ignore into versions (path, epoch) values %s;'
           % ','.join(version_inserts))
      cursor.execute(s)
      cursor.execute('commit;')
      version_inserts = []

    if version_updates:
      s = ('update versions set media_%s="N" where '
           'concat_ws("~", path, epoch) in (%s);'
           %(FLAGS.media, ','.join(version_updates)))
      cursor.execute(s)
      cursor.execute('commit;')
      version_updates = []

  except MySQLdb.Error, (errno, errstr):
    if errno in [1213, 2006, 2013] and retry:
      # Deadlock // lost connection // server gone away, retry
      CommitChanges(cursor, retry=False)

    else:
      print '%s: MySQL Exception %s %s' %(datetime.datetime.now(),
                                          errno, errstr)
      TraceBack()
      print
      print '%s: Nearest SQL was: %s' %(datetime.datetime.now(), s[:300])

  except Exception, e:
    print '%s: Exception %s' %(datetime.datetime.now(), e)
    TraceBack()
    print
    print '%s: Nearest SQL was: %s' %(datetime.datetime.now(), s[:300])

  db_time += time.time() - db_start


def SaveBackupFile(cursor, target, backup_file, elements):
  CommitChanges(cursor)

  s = ('insert ignore into entities (target, backup_file) '
       'values(%s, %s);'
       %(sql.FormatSqlValue('target', target),
         sql.FormatSqlValue('backup_file', backup_file)))
  cursor.execute(s)
  cursor.execute('commit;')

  s = ('update entities set elements=%d, media_%s="N" where '
       'target=%s and backup_file=%s;'
       %(elements, FLAGS.media,
         sql.FormatSqlValue('target', target),
         sql.FormatSqlValue('backup_file', backup_file)))
  cursor.execute(s)
  cursor.execute('commit;')


def ProcessBackup(cursor, path):
  global filesystem_inserts
  global version_inserts
  global version_updates

  target = path[len(FLAGS.path):]
  if not target:
    target = '/'

  print
  print '%s: Checking %s (from %s)' %(datetime.datetime.now(), target, path)

  now = datetime.datetime.now()
  cmd = '%s/listfiles.sh %04d%02d%02d %s' %(SCRIPTS_PATH, now.year, now.month,
                                            now.day, path)
  
  backup_file = None
  elements = 0

  out = cachedexecution.Run(cmd, maxage=24 * 60 * 60)
  cache_file = open('listfiles.out/%s' % path.replace('/', '_'), 'w')

  for l in out:
    cache_file.write(l)
    l = l.rstrip()

    try:
      m = FILE_RE.match(l)
      if l == 'Last full backup date: none':
        return None

      elif l.startswith('Local and Remote metadata are synchronized'):
        pass
      elif l.startswith('Warning, found incomplete backup sets'):
        pass
      elif l.startswith('Last full backup date'):
        pass
      elif l.startswith('Copying duplicity'):
        pass
      elif l.startswith('Synchronising remote metadata'):
        pass
      elif l.startswith('No signature chain for the requested time'):
        pass
      elif l.startswith('Deleting local'):
        pass

      elif l.startswith('Backup file: '):
        if backup_file and not skip_backup_file:
          SaveBackupFile(cursor, target, backup_file, elements)

        _, backup_file = os.path.split(l[len('Backup file: '):])
        cursor.execute('select * from entities where target=%s and '
                       'backup_file=%s and media_%s="N";'
                       %(sql.FormatSqlValue('target', target),
                         sql.FormatSqlValue('backup_file', backup_file),
                         FLAGS.media))
        if cursor.rowcount > 0:
          skip_backup_file = True
          print ('%s: ... skipping already seen %s'
                 %(datetime.datetime.now(), backup_file))
        else:
          skip_backup_file = False

      elif not m:
        print ('%s: Failed to parse file entry: %s'
               %(datetime.datetime.now(), l))

      elif not skip_backup_file:
        (directory, filename) = os.path.split(m.group(1))
        filetype = m.group(2)
        epoch = int(m.group(3))

        # Filesystem entry
        parent = os.path.join(target, directory).rstrip('/')
        filesystem_inserts.append('(%s, %s)'
                                  %(sql.FormatSqlValue('filename', filename),
                                    sql.FormatSqlValue('parent', parent)))

        # This version of the file
        path = sql.FormatSqlValue('path', os.path.join(target, directory,
                                                       filename))
       

        version_inserts.append('(%s, %s)' %(path, epoch))
        version_updates.append(sql.FormatSqlValue('seen', \
            '%s~%s' %(os.path.join(target, directory, filename), epoch)))

        elements += 1
        if elements % 1000 == 0:
          CommitChanges(cursor)
          print '%s:     ... %d elements' %(datetime.datetime.now(), elements)

    except sql.FormatException, e:
      print ('%s: %s: SQL format exception %s'
             %(datetime.datetime.now(), path, e))
      f = open('listfiles.problems', 'w+')
      f.write('%s: SQL format exception %s\n' %(path, e))
      f.close()

    except Exception, e:
      exc = None
      print '%s: %s: Exception %s' %(datetime.datetime.now(), path, e)

      try:
        exc = sys.exc_info()
        for tb in traceback.format_exception(exc[0], exc[1], exc[2]):
          print '  %s' % tb
        del tb

      finally:
        del exc

      sys.exit(1)

  cache_file.close()
  CommitChanges(cursor)


def RecurseDirectory(cursor, path):
  if len(path) > len(FLAGS.path):
    target = path[len(FLAGS.path):].rstrip('/')
    p, f = os.path.split(target)
    s = ('insert ignore into filesystem (parent, filename) values (%s, %s);'
         %(sql.FormatSqlValue('parent', p),
           sql.FormatSqlValue('filesystem', f)))
    cursor.execute(s)
    cursor.execute('commit;')

  for ent in os.listdir(path):
    if os.path.isdir(os.path.join(path, ent)):
      RecurseDirectory(cursor, os.path.join(path, ent))

  ProcessBackup(cursor, path)
  PrintProgress(cursor)


def main(argv):
  global processing_queue
  global total_days
  global completed_days

  # Parse flags
  try:
    argv = FLAGS(argv)

  except gflags.FlagsError, e:
    print 'Flags error: %s' % e
    print
    print FLAGS

  if not FLAGS.media:
    print 'Please specify the name of this backup set with --media'
    sys.exit(1)

  if not FLAGS.path:
    print 'Please specify the path to this backup set with --path'
    sys.exit(1)

  db = MySQLdb.connect(user = FLAGS.dbuser, db = FLAGS.dbname,
                       passwd = FLAGS.dbpassword)
  cursor = db.cursor(MySQLdb.cursors.DictCursor)

  print '%s: Tweaking database schema' % datetime.datetime.now()
  try:
    cursor.execute('alter table versions add column media_%s varchar(1);'
                   % FLAGS.media)
    cursor.execute('alter table versions add index(media_%s);'
                   % FLAGS.media)
    cursor.execute('commit;')
  except:
    pass

  # This just creates a queue of directories to process
  RecurseDirectory(cursor, FLAGS.path)

if __name__ == "__main__":
  main(sys.argv)
