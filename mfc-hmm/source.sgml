<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook V4.1//EN">
<article>
<title>Computer Engineering Four Assignment Two</title>
   <subtitle>Speech Recognition</subtitle>

<articleinfo>
<author>
  <firstname>Michael</firstname>
  <surname>Still</surname>
  <affiliation>
    <jobtitle>964076</jobtitle>
  </affiliation>
</author>
</articleinfo>

<sect1>
<title>Question One</title>

<sect2><title>Comment dhmm.cpp and dhmm.h</title>
<para>
The following source files are my commented versions. All of the comments I have added start with the text <quote>Mikal: </quote> in order to more clearly identify them.
</para>

<execute><cmd>code2db</cmd><args>3</args><input>dhmm.h</input></execute>
<execute><cmd>code2db</cmd><args>3</args><input>dhmm.cpp</input></execute>

</sect2>

<sect2><title>User manual for DhmmTrain</title>
<sect3><title>Purpose</title>
<para>
This application is used to train a Hidden Markov Model with a series of observations of utterances. The observations need to be pre-encoded with a given Vector Quantization codebook. The end result of the program is a trained Hidden Markov Model, which can then be used by the <emphasis>test</emphasis> application to perform recognition of unknown utterances.
</para>
</sect3>

<sect3><title>Usage</title>
<para>
The <emphasis>train</emphasis> application takes a script file and the name of the output Hidden Markov Model file as arguements. The script file contains a list of Vector Quantized observations to train the Hidden markov Model with, with one per line. The output file has the A and B matrices, as well as the pi vector written to it.
</para>

<para>
A sample command line is:
</para>

<programlisting>
./train script-train d001.hmm
</programlisting>
</sect3>

<sect3><title>Input and output file structures</title>
<para>
The script file is a list of the observations to use to train this Hidden Markov Model. It has the following format:
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>script-test</input></execute>
</programlisting>

<para>
Each observation file is a list of the Vector Quantized vectors which matched that observation. It has the following format:
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>s031d00x.cod</input></execute>
</programlisting>

<para>
The application will produce the following output (indented lines imply a continuation of the previous line):
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>d001.hmm</input></execute>
</programlisting>

<para>
This output is the A matrix (5 lines of 5 entries), the B matrix (5 by the number of observations), and the Pi vector (the last five lines).
</para>
</sect3>
</sect2>

<sect2><title>Program output</title>
<para>
The following output is generated for the three different digits. Note that this matches the output generated by Dr Wagner's reference implementation.
</para>

<sect3><title>Digit 001</title>
<para>
The running program produces the following output:
</para>

<programlisting>
<execute><cmd>train</cmd><args>script-d001 d001.hmm</args></execute>
</programlisting>

<para>
The trained HMM is as follows (indented lines imply a continuation of the previous line):
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>d001.hmm</input></execute>
</programlisting>
</sect3>

<sect3><title>Digit 002</title>
<para>
The running program produces the following output:
</para>

<programlisting>
<execute><cmd>train</cmd><args>script-d002 d002.hmm</args></execute>
</programlisting>

<para>
The trained HMM is as follows (indented lines imply a continuation of the previous line):
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>d002.hmm</input></execute>
</programlisting>
</sect3>

<sect3><title>Digit 003</title>
<para>
The running program produces the following output:
</para>

<programlisting>
<execute><cmd>train</cmd><args>script-d003 d003.hmm</args></execute>
</programlisting>

<para>
The trained HMM is as follows (indented lines imply a continuation of the previous line):
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>d003.hmm</input></execute>
</programlisting>
</sect3>

</sect2>
</sect1>

<sect1><title>Question Two</title>
<para>
In this part, an application is developed to use these Hidden Markov Models to determine which is the most likely candidate for the unknown utterance.
</para>

<sect2><title>Implement LogLikelihood and Read</title>
<para>
These methods are implemented in the code shown in question one, but is repeated below for ease of reference:
</para>

<programlisting>
//////////////////////////////////////////////////////////////////////
// Mikal: Determine the probability that the passed observation
// matches this HMM. Return the log of the probability
//////////////////////////////////////////////////////////////////////

double CDhmm::LogLikelihood(const obs &amp;oneObservation) const
{
  double logp = 0.0;
  int   i, j, t;
  
  // Mikal: Allocate memory for the alpha matrix, the beta vector,
  // the next beta vector, and the scale vector
  double **alpha = new double* [oneObservation.size()];
  for (t=0; t&lt;oneObservation.size(); t++)
    alpha[t] = new double [NSTATES];
  double *beta = new double [NSTATES];
  double *nxtbeta = new double [NSTATES];
  double *scale = new double [oneObservation.size()];
  
  // Mikal: The forward algorithm for each of the values in the observation
  for (t=0; t&lt;oneObservation.size(); t++)
    {
      scale[t] = 0.0;
      for (i=0; i&lt;NSTATES; i++)
	{
	  // Mikal: Forward algorithm initialization
	  if (t==0)
	    alpha[t][i] = pi[i] * B[i][oneObservation[t]];
	  
	  // Mikal: Induction
	  else
	    {
	      alpha[t][i] = 0.0;
	      for (j=0; j&lt;NSTATES; j++)
                alpha[t][i] += alpha[t-1][j] * A[j][i];
	      alpha[t][i] *= B[i][oneObservation[t]];
	    }
	  
	  // Mikal: Termination
	  scale[t] += alpha[t][i];
	}
      
      if (scale[t] &lt; SMALL_NO)
        scale[t] = SMALL_NO;
      logp += log10(scale[t]);
      
      for (i=0; i&lt;NSTATES; i++)
        alpha[t][i] /= scale[t];
    }

  // Mikal: Cleanup
  for (t=0; t&lt;oneObservation.size(); t++)
    delete [] alpha[t];
  delete [] alpha;
  delete [] beta;
  delete [] nxtbeta;
  delete [] scale;

  return logp;
}
</programlisting>
</sect2>

<sect2><title>Develop a testing application</title>
<para>
Apart from the <emphasis>LogLikelihood</emphasis> and <emphasis>Read</emphasis> methods, another source file, <emphasis>test.cpp</emphasis> was developed. <emphasis>test.cpp</emphasis> is as follows:
</para>

<execute><cmd>code2db</cmd><args>3</args><input>test.cpp</input></execute>

<sect3><title>Example execution</title>
<para>
Refer to the user manual below for an example operation. The application selects the digit <emphasis>two</emphasis> as the most likely.
</para>
</sect3>
</sect2>

<sect2><title>User manual</title>
<sect3><title>Purpose</title>
<para>
The <emphasis>test</emphasis> application is used to determine which of the Hidden Markov Models most closely matches the observation which is being tested. This is done by determining the probability that the observation matches each of the Hidden Markov Models. The model with the highest probability is then declared to be the winner.
</para>

<para>
Refer to the output section below of the output from the matching sequence for the unknown utterance.
</para>
</sect3>

<sect3><title>Usage</title>
<para>
The <emphasis>test</emphasis> application takes a script file and an observation file, and uses the Hidden Markov Models listed in the script file to determine probabilities that the observation matches that any of those models.
</para>

<para>
A sample command line is:
</para>

<programlisting>
./test script-test s031d00x.cod
</programlisting>
</sect3>

<sect3><title>Input and output file structures</title>
<para>
The script file has the following format:
</para>

<execute><cmd>code2db</cmd><input>script-test</input></execute>

<para>
The observation file is a list of the Vector Quantized vectors which matched that observation. It has the following format:
</para>

<execute><cmd>code2db</cmd><input>s031d00x.cod</input></execute>

<para>
The Hidden Markov Model file is the A matrix (5 lines of 5 entries), the B matrix (5 by the number of observations), and the Pi vector (the last five lines). For example:
</para>

<programlisting>
<execute><cmd>linebreak</cmd><args>60 5</args><input>d001.hmm</input></execute>
</programlisting>

<para>
The application will produce the following output:
</para>

<programlisting>
<execute><cmd>./test</cmd><args>script-test s031d00x.cod</args></execute>
</programlisting>
</sect3>
</sect2>
</sect1>
</article>
